{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from typing import Literal, Iterable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from qresearch.backtest.portfolio import backtest_weights, TRADING_DAYS\n",
    "from typing import Union, Sequence, Optional, Tuple\n",
    "import yfinance as yf\n",
    "\n",
    "Tickers = Union[str, Sequence[str]]\n",
    "\n",
    "def _standardize_index(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "    df = df.sort_index()\n",
    "    # enforce tz-naive\n",
    "    if df.index.tz is not None:\n",
    "        df.index = df.index.tz_convert(None)\n",
    "    return df\n",
    "\n",
    "\n",
    "def download_ohlc_yf(\n",
    "    tickers: Tickers,\n",
    "    start: str,\n",
    "    end: Optional[str] = None,\n",
    "    *,\n",
    "    auto_adjust: bool = False,\n",
    "    ffill: bool = True,\n",
    "    drop_all_nan_rows: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Download OHLC(+Adj Close, Volume) from Yahoo via yfinance.\n",
    "\n",
    "    Behavior:\n",
    "    - If tickers is a single str: returns a FLAT-column DataFrame with columns\n",
    "      [\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\"] (subset if missing).\n",
    "    - If tickers is a list/sequence: returns a MultiIndex DataFrame with columns\n",
    "      (Field, Ticker) using the canonical orientation.\n",
    "\n",
    "    Notes:\n",
    "    - For indices like ^GSPC, yfinance typically provides OHLC and Adj Close.\n",
    "    \"\"\"\n",
    "    if isinstance(tickers, str):\n",
    "        tick_list = [tickers]\n",
    "        single = True\n",
    "    else:\n",
    "        tick_list = list(tickers)\n",
    "        single = False\n",
    "\n",
    "    raw = yf.download(\n",
    "        tick_list,\n",
    "        start=start,\n",
    "        end=end,\n",
    "        auto_adjust=auto_adjust,\n",
    "        progress=False,\n",
    "        group_by=\"column\",   # most stable output; can still be MultiIndex for multiple tickers\n",
    "        threads=True,\n",
    "    )\n",
    "    if raw is None or raw.empty:\n",
    "        raise ValueError(\"yfinance returned empty data\")\n",
    "\n",
    "    raw = _standardize_index(raw)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Single ticker -> flatten\n",
    "    # -----------------------------\n",
    "    if single:\n",
    "        if isinstance(raw.columns, pd.MultiIndex):\n",
    "            # normalize to (Field, Ticker)\n",
    "            lvl0 = raw.columns.get_level_values(0)\n",
    "            if all(t in tick_list for t in set(lvl0)):\n",
    "                raw = raw.swaplevel(0, 1, axis=1)  # (Field, Ticker)\n",
    "            # slice the only ticker\n",
    "            raw = raw.xs(tick_list[0], axis=1, level=1, drop_level=True)\n",
    "\n",
    "        # now should be flat columns\n",
    "        needed = {\"High\", \"Low\", \"Close\"}\n",
    "        if not needed.issubset(set(raw.columns)):\n",
    "            raise ValueError(\n",
    "                f\"Downloaded data missing required columns {needed}. Got: {list(raw.columns)}\"\n",
    "            )\n",
    "\n",
    "        # keep canonical field ordering if present\n",
    "        fields = [f for f in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"] if f in raw.columns]\n",
    "        out = raw[fields].copy()\n",
    "\n",
    "        out = out.replace([np.inf, -np.inf], np.nan)\n",
    "        if ffill:\n",
    "            out = out.ffill()\n",
    "        if drop_all_nan_rows:\n",
    "            out = out.dropna(how=\"all\")\n",
    "        return out\n",
    "\n",
    "    # -----------------------------\n",
    "    # Multi ticker -> MultiIndex (Field, Ticker)\n",
    "    # -----------------------------\n",
    "    if not isinstance(raw.columns, pd.MultiIndex):\n",
    "        # defensive: yfinance sometimes returns flat if only 1 ticker; but we are in multi mode\n",
    "        raise ValueError(\"Expected MultiIndex columns for multiple tickers, got flat columns.\")\n",
    "\n",
    "    # normalize to (Field, Ticker)\n",
    "    lvl0 = raw.columns.get_level_values(0)\n",
    "    if all(t in tick_list for t in set(lvl0)):\n",
    "        raw = raw.swaplevel(0, 1, axis=1)\n",
    "\n",
    "    raw = raw.sort_index(axis=1)\n",
    "\n",
    "    # keep canonical fields if present\n",
    "    fields_keep = [f for f in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]\n",
    "                   if f in raw.columns.get_level_values(0)]\n",
    "    out = raw.loc[:, (fields_keep, tick_list)].copy()\n",
    "\n",
    "    out = out.replace([np.inf, -np.inf], np.nan)\n",
    "    if ffill:\n",
    "        out = out.ffill()\n",
    "    if drop_all_nan_rows:\n",
    "        out = out.dropna(how=\"all\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def _rolling_rsrs_beta_r2(\n",
    "    high: pd.Series,\n",
    "    low: pd.Series,\n",
    "    n: int = 18,\n",
    ") -> Tuple[pd.Series, pd.Series]:\n",
    "    \"\"\"\n",
    "    Rolling simple regression: High = alpha + beta * Low, window=n\n",
    "\n",
    "    Returns:\n",
    "      beta: rolling slope\n",
    "      r2:   rolling R^2\n",
    "\n",
    "    Implementation is vectorized using rolling moments:\n",
    "      beta = cov(Low, High) / var(Low)\n",
    "      R^2  = corr(Low, High)^2 = cov^2 / (var(Low)*var(High))   (for simple regression with intercept)\n",
    "\n",
    "    Notes:\n",
    "    - Uses ddof=0 consistency with your z-score std(ddof=0).\n",
    "    - Handles divide-by-zero by returning NaN where not defined.\n",
    "    \"\"\"\n",
    "    high = pd.Series(high).astype(float)\n",
    "    low = pd.Series(low).astype(float)\n",
    "    idx = high.index.intersection(low.index)\n",
    "    high = high.reindex(idx)\n",
    "    low = low.reindex(idx)\n",
    "\n",
    "    # rolling means\n",
    "    mx = low.rolling(n).mean()\n",
    "    my = high.rolling(n).mean()\n",
    "\n",
    "    # rolling second moments\n",
    "    mxx = (low * low).rolling(n).mean()\n",
    "    myy = (high * high).rolling(n).mean()\n",
    "    mxy = (low * high).rolling(n).mean()\n",
    "\n",
    "    varx = mxx - mx * mx\n",
    "    vary = myy - my * my\n",
    "    cov = mxy - mx * my\n",
    "\n",
    "    # beta\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        beta = cov / varx\n",
    "\n",
    "    # r2 = corr^2\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        r2 = (cov * cov) / (varx * vary)\n",
    "\n",
    "    beta = beta.replace([np.inf, -np.inf], np.nan)\n",
    "    r2 = r2.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # Clip r2 to [0,1] where numerical noise occurs\n",
    "    r2 = r2.clip(lower=0.0, upper=1.0)\n",
    "\n",
    "    beta.name = \"beta\"\n",
    "    r2.name = \"r2\"\n",
    "    return beta, r2\n"
   ],
   "id": "cc18e0a6c5eb7ecd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# =========================================================\n",
    "# 0) Assumptions (you already have these in your project)\n",
    "# =========================================================\n",
    "# - download_ohlc_yf(ticker, start, end, auto_adjust=False) -> DataFrame with columns:\n",
    "#   [\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\"] (some may be missing)\n",
    "# - _rolling_rsrs_beta_r2(high: Series, low: Series, n: int) -> (beta Series, r2 Series)\n",
    "#\n",
    "# If your function name differs (e.g., download_ohlc), just rename below.\n",
    "\n",
    "# =========================================================\n",
    "# 1) RSRS definitions\n",
    "# =========================================================\n",
    "RSRSVariant = Literal[\"z\", \"z_adj\", \"z_right\"]\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RSRSParams:\n",
    "    n: int\n",
    "    m: int\n",
    "    s: float\n",
    "    variant: RSRSVariant\n",
    "    ma_len: int  # 0 => disable MA filter (price_filter=False)\n",
    "\n",
    "def rsrs_indicator(\n",
    "    ohlc: pd.DataFrame,\n",
    "    n: int = 18,\n",
    "    m: int = 600,\n",
    "    variant: RSRSVariant = \"z_right\",\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Compute RSRS indicator series on the same date index as ohlc.\n",
    "    - n: regression window for beta and r2\n",
    "    - m: standardization window for beta z-score\n",
    "    - variant:\n",
    "        z       = zscore(beta)\n",
    "        z_adj   = z * r2\n",
    "        z_right = (z * r2) * beta\n",
    "    \"\"\"\n",
    "    beta, r2 = _rolling_rsrs_beta_r2(high=ohlc[\"High\"], low=ohlc[\"Low\"], n=n)\n",
    "\n",
    "    mu = beta.rolling(m).mean()\n",
    "    sd = beta.rolling(m).std(ddof=0)\n",
    "    z = (beta - mu) / sd\n",
    "\n",
    "    z_adj = z * r2\n",
    "    z_right = z_adj * beta\n",
    "\n",
    "    return {\"z\": z, \"z_adj\": z_adj, \"z_right\": z_right}[variant]\n",
    "\n",
    "def rsrs_weights_from_score(\n",
    "    score: pd.Series,\n",
    "    close: pd.Series,\n",
    "    trade_ticker: str,\n",
    "    s: float,\n",
    "    ma_len: int = 20,\n",
    "    ma_compare_lag1: int = 1,\n",
    "    ma_compare_lag2: int = 3,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    LONG-ONLY in/out timing weights for a single traded ticker, using precomputed score.\n",
    "    Decision-time weights (as-of close t), UN-SHIFTED; backtest_weights() shifts by 1.\n",
    "\n",
    "    Hysteresis rules:\n",
    "      - if score_t < -s: weight = 0\n",
    "      - else if score_t >  s: weight = 1, with optional MA filter\n",
    "      - else: hold previous weight\n",
    "\n",
    "    MA filter enabled iff ma_len > 0:\n",
    "      MA(t-lag1) > MA(t-lag2)\n",
    "    \"\"\"\n",
    "    idx = score.index\n",
    "    close = close.reindex(idx).astype(float)\n",
    "\n",
    "    if ma_len and ma_len > 0:\n",
    "        ma = close.rolling(ma_len).mean()\n",
    "        ma_ok = ma.shift(ma_compare_lag1) > ma.shift(ma_compare_lag2)\n",
    "    else:\n",
    "        ma_ok = pd.Series(True, index=idx)\n",
    "\n",
    "    w = pd.Series(0.0, index=idx, dtype=float)\n",
    "    state = 0.0\n",
    "\n",
    "    # Use .to_numpy() for speed\n",
    "    sc = score.to_numpy()\n",
    "    ok = ma_ok.to_numpy()\n",
    "\n",
    "    for i in range(len(w)):\n",
    "        it = sc[i]\n",
    "        if not np.isfinite(it):\n",
    "            w.iat[i] = state\n",
    "            continue\n",
    "\n",
    "        if it < -s:\n",
    "            state = 0.0\n",
    "        elif it > s:\n",
    "            if bool(ok[i]):\n",
    "                state = 1.0\n",
    "            # else: hold state\n",
    "        # else: hold state\n",
    "\n",
    "        w.iat[i] = state\n",
    "\n",
    "    return pd.DataFrame({trade_ticker: w}, index=idx)\n",
    "\n",
    "# =========================================================\n",
    "# 2) Performance stats (same as your style)\n",
    "# =========================================================\n",
    "def perf_stats(returns: pd.Series, trading_days: int = TRADING_DAYS) -> dict[str, float]:\n",
    "    r = returns.fillna(0.0)\n",
    "    eq = (1.0 + r).cumprod()\n",
    "    dd = eq / eq.cummax() - 1.0\n",
    "\n",
    "    ann_ret = (eq.iat[-1] ** (trading_days / max(1, len(eq))) - 1.0) if len(eq) > 1 else 0.0\n",
    "    ann_vol = float(r.std(ddof=0) * np.sqrt(trading_days)) if len(r) > 1 else 0.0\n",
    "    sharpe = (ann_ret / ann_vol) if ann_vol > 1e-12 else np.nan\n",
    "    max_dd = float(dd.min()) if len(dd) else 0.0\n",
    "    return {\n",
    "        \"ann_ret\": float(ann_ret),\n",
    "        \"ann_vol\": float(ann_vol),\n",
    "        \"sharpe\": float(sharpe),\n",
    "        \"max_dd\": float(max_dd),\n",
    "        \"total_return\": float(eq.iat[-1] - 1.0) if len(eq) else 0.0,\n",
    "    }\n",
    "\n",
    "# =========================================================\n",
    "# 3) Walk-forward window generator\n",
    "# =========================================================\n",
    "def walkforward_year_windows(\n",
    "    index: pd.DatetimeIndex,\n",
    "    train_years: int = 5,\n",
    "    test_years: int = 1,\n",
    "    step_years: int = 1,\n",
    ") -> list[tuple[pd.Timestamp, pd.Timestamp, pd.Timestamp, pd.Timestamp]]:\n",
    "    \"\"\"\n",
    "    Returns list of (train_start, train_end, test_start, test_end), inclusive ends.\n",
    "    \"\"\"\n",
    "    idx = pd.DatetimeIndex(index).sort_values()\n",
    "    start = idx.min()\n",
    "    end = idx.max()\n",
    "\n",
    "    windows = []\n",
    "    cur_train_start = start\n",
    "\n",
    "    while True:\n",
    "        train_end = cur_train_start + pd.DateOffset(years=train_years) - pd.DateOffset(days=1)\n",
    "        test_start = train_end + pd.DateOffset(days=1)\n",
    "        test_end = test_start + pd.DateOffset(years=test_years) - pd.DateOffset(days=1)\n",
    "\n",
    "        if test_end > end:\n",
    "            break\n",
    "\n",
    "        # Snap to available trading dates (next/prev)\n",
    "        ts = idx[idx >= cur_train_start]\n",
    "        if len(ts) == 0:\n",
    "            break\n",
    "        train_start2 = ts[0]\n",
    "\n",
    "        te = idx[idx <= train_end]\n",
    "        if len(te) == 0:\n",
    "            break\n",
    "        train_end2 = te[-1]\n",
    "\n",
    "        tss = idx[idx >= test_start]\n",
    "        if len(tss) == 0:\n",
    "            break\n",
    "        test_start2 = tss[0]\n",
    "\n",
    "        tee = idx[idx <= test_end]\n",
    "        if len(tee) == 0:\n",
    "            break\n",
    "        test_end2 = tee[-1]\n",
    "\n",
    "        windows.append((train_start2, train_end2, test_start2, test_end2))\n",
    "\n",
    "        # step forward\n",
    "        cur_train_start = cur_train_start + pd.DateOffset(years=step_years)\n",
    "\n",
    "    return windows\n",
    "\n",
    "# =========================================================\n",
    "# 4) Grid (FAST) â€” keep small to avoid long runtime\n",
    "# =========================================================\n",
    "def make_fast_grid() -> list[RSRSParams]:\n",
    "    # Recommended fast grid\n",
    "    variants: list[RSRSVariant] = [\"z_right\"]  # add \"z_adj\" later if you want\n",
    "    ns = [16, 18]\n",
    "    ms = [250, 300, 600]\n",
    "    ss = [0.5, 0.6, 0.7, 0.8]\n",
    "    mas = [0, 8, 20]  # 0 => disable MA filter\n",
    "\n",
    "    out: list[RSRSParams] = []\n",
    "    for n, m, s, v, ma in product(ns, ms, ss, variants, mas):\n",
    "        out.append(RSRSParams(n=n, m=m, s=s, variant=v, ma_len=ma))\n",
    "    return out\n",
    "\n",
    "# =========================================================\n",
    "# 5) Core runner: one ticker, walk-forward OOS, select max Sharpe on train\n",
    "# =========================================================\n",
    "def run_rsrs_oos_one_ticker(\n",
    "    trade_ticker: str,\n",
    "    start: str,\n",
    "    end: str,\n",
    "    grid: Iterable[RSRSParams],\n",
    "    *,\n",
    "    train_years: int = 5,\n",
    "    test_years: int = 1,\n",
    "    step_years: int = 1,\n",
    "    fee_bps: float = 0.0,\n",
    "    rf_annual: float = 0.0,\n",
    "    long_only: bool = True,\n",
    "    allow_leverage: bool = False,\n",
    "    fill_weights: Literal[\"zero\", \"ffill\", \"error\"] = \"zero\",\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - wf_rows: per-window selection rows\n",
    "      - param_summary: grouped by params across OOS windows\n",
    "      - oos_summary: single-row summary for the concatenated OOS equity\n",
    "    \"\"\"\n",
    "    # ---- download OHLC ----\n",
    "    ohlc = download_ohlc_yf(trade_ticker, start=start, end=end, auto_adjust=False)\n",
    "    ohlc = ohlc.sort_index()\n",
    "\n",
    "    # tradable price series\n",
    "    px_col = \"Adj Close\" if \"Adj Close\" in ohlc.columns else \"Close\"\n",
    "    px = ohlc[px_col].astype(float)\n",
    "    prices = pd.DataFrame({trade_ticker: px}, index=ohlc.index)\n",
    "\n",
    "    # precompute scores + weights once per param (big speed-up)\n",
    "    close = ohlc[\"Close\"].astype(float)\n",
    "    weights_cache: dict[RSRSParams, pd.DataFrame] = {}\n",
    "\n",
    "    for p in grid:\n",
    "        score = rsrs_indicator(ohlc=ohlc, n=p.n, m=p.m, variant=p.variant)\n",
    "        w = rsrs_weights_from_score(\n",
    "            score=score,\n",
    "            close=close,\n",
    "            trade_ticker=trade_ticker,\n",
    "            s=p.s,\n",
    "            ma_len=p.ma_len,\n",
    "            ma_compare_lag1=1,\n",
    "            ma_compare_lag2=3,\n",
    "        )\n",
    "        weights_cache[p] = w\n",
    "\n",
    "    # walk-forward windows\n",
    "    windows = walkforward_year_windows(\n",
    "        ohlc.index, train_years=train_years, test_years=test_years, step_years=step_years\n",
    "    )\n",
    "\n",
    "    wf_rows = []\n",
    "    oos_net_rets = []\n",
    "\n",
    "    for (train_start, train_end, test_start, test_end) in windows:\n",
    "        # ---- select best params on TRAIN (max Sharpe) ----\n",
    "        best_p = None\n",
    "        best_metric = -np.inf\n",
    "\n",
    "        for p in grid:\n",
    "            w_full = weights_cache[p]\n",
    "            pr_tr = prices.loc[train_start:train_end]\n",
    "            w_tr = w_full.loc[train_start:train_end]\n",
    "\n",
    "            if len(pr_tr) < 5 or len(w_tr) < 5:\n",
    "                continue\n",
    "\n",
    "            res_tr = backtest_weights(\n",
    "                prices=pr_tr,\n",
    "                weights=w_tr,\n",
    "                fee_bps=fee_bps,\n",
    "                rf_annual=rf_annual,\n",
    "                long_only=long_only,\n",
    "                allow_leverage=allow_leverage,\n",
    "                fill_weights=fill_weights,\n",
    "            )\n",
    "            st_tr = perf_stats(res_tr.net_ret)\n",
    "            metric = st_tr[\"sharpe\"]\n",
    "\n",
    "            if np.isfinite(metric) and metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_p = p\n",
    "\n",
    "        if best_p is None:\n",
    "            # no valid selection; skip this window\n",
    "            continue\n",
    "\n",
    "        # ---- evaluate best params on TEST ----\n",
    "        w_full = weights_cache[best_p]\n",
    "        pr_te = prices.loc[test_start:test_end]\n",
    "        w_te = w_full.loc[test_start:test_end]\n",
    "\n",
    "        res_te = backtest_weights(\n",
    "            prices=pr_te,\n",
    "            weights=w_te,\n",
    "            fee_bps=fee_bps,\n",
    "            rf_annual=rf_annual,\n",
    "            long_only=long_only,\n",
    "            allow_leverage=allow_leverage,\n",
    "            fill_weights=fill_weights,\n",
    "        )\n",
    "        st_te = perf_stats(res_te.net_ret)\n",
    "\n",
    "        wf_rows.append({\n",
    "            \"ticker\": trade_ticker,\n",
    "            \"train_start\": train_start,\n",
    "            \"train_end\": train_end,\n",
    "            \"test_start\": test_start,\n",
    "            \"test_end\": test_end,\n",
    "            \"sel_metric_train\": float(best_metric),\n",
    "            \"n\": best_p.n,\n",
    "            \"m\": best_p.m,\n",
    "            \"s\": best_p.s,\n",
    "            \"variant\": best_p.variant,\n",
    "            \"ma_len\": best_p.ma_len,\n",
    "            \"oos_ann_ret\": st_te[\"ann_ret\"],\n",
    "            \"oos_ann_vol\": st_te[\"ann_vol\"],\n",
    "            \"oos_sharpe\": st_te[\"sharpe\"],\n",
    "            \"oos_max_dd\": st_te[\"max_dd\"],\n",
    "            \"oos_total_return\": st_te[\"total_return\"],\n",
    "            \"oos_avg_exposure\": float(res_te.exposure.mean()) if len(res_te.exposure) else 0.0,\n",
    "            \"oos_turnover\": float(res_te.turnover.sum()) if len(res_te.turnover) else 0.0,\n",
    "        })\n",
    "\n",
    "        oos_net_rets.append(res_te.net_ret.rename(test_start))\n",
    "\n",
    "    wf_df = pd.DataFrame(wf_rows)\n",
    "    if wf_df.empty:\n",
    "        return wf_df, pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    # ---- param summary across OOS windows ----\n",
    "    gcols = [\"n\", \"m\", \"s\", \"variant\", \"ma_len\"]\n",
    "    param_summary = (\n",
    "        wf_df.groupby(gcols)\n",
    "        .agg(\n",
    "            mean_oos_sharpe=(\"oos_sharpe\", \"mean\"),\n",
    "            med_oos_sharpe=(\"oos_sharpe\", \"median\"),\n",
    "            mean_oos_ann_ret=(\"oos_ann_ret\", \"mean\"),\n",
    "            mean_oos_max_dd=(\"oos_max_dd\", \"mean\"),\n",
    "            n_windows=(\"oos_sharpe\", \"count\"),\n",
    "        )\n",
    "        .sort_values(\"mean_oos_sharpe\", ascending=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # ---- concatenated OOS equity (stitch test windows) ----\n",
    "    # concatenate net returns in chronological order (they are separate test windows)\n",
    "    oos_all = pd.concat([s for s in oos_net_rets], axis=0).sort_index()\n",
    "    oos_summary = pd.DataFrame([{\n",
    "        \"ticker\": trade_ticker,\n",
    "        **{f\"oos_{k}\": v for k, v in perf_stats(oos_all).items()},\n",
    "    }])\n",
    "\n",
    "    return wf_df, param_summary, oos_summary\n",
    "\n",
    "# =========================================================\n",
    "# 6) Multi-market runner + saving outputs\n",
    "# =========================================================\n",
    "def run_multi_market_rsrs_oos(\n",
    "    tickers: list[str],\n",
    "    *,\n",
    "    start: str,\n",
    "    end: str,\n",
    "    out_dir: str = \"./rsrs_oos_runs\",\n",
    "    train_years: int = 5,\n",
    "    test_years: int = 1,\n",
    "    step_years: int = 1,\n",
    "    fee_bps: float = 0.0,\n",
    "    rf_annual: float = 0.0,\n",
    ") -> None:\n",
    "    grid = make_fast_grid()\n",
    "\n",
    "    out_path = Path(out_dir)\n",
    "    out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    all_wf = []\n",
    "    all_param = []\n",
    "    all_oos = []\n",
    "\n",
    "    for t in tickers:\n",
    "        wf_df, param_df, oos_df = run_rsrs_oos_one_ticker(\n",
    "            trade_ticker=t,\n",
    "            start=start,\n",
    "            end=end,\n",
    "            grid=grid,\n",
    "            train_years=train_years,\n",
    "            test_years=test_years,\n",
    "            step_years=step_years,\n",
    "            fee_bps=fee_bps,\n",
    "            rf_annual=rf_annual,\n",
    "        )\n",
    "\n",
    "        if not wf_df.empty:\n",
    "            all_wf.append(wf_df)\n",
    "        if not param_df.empty:\n",
    "            param_df = param_df.copy()\n",
    "            param_df.insert(0, \"ticker\", t)\n",
    "            all_param.append(param_df)\n",
    "        if not oos_df.empty:\n",
    "            all_oos.append(oos_df)\n",
    "\n",
    "        # per-ticker save (so you never lose partial work)\n",
    "        stamp = pd.Timestamp.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        wf_df.to_csv(out_path / f\"{t}_walkforward_{stamp}.csv\", index=False)\n",
    "        param_df.to_csv(out_path / f\"{t}_param_summary_{stamp}.csv\", index=False)\n",
    "        oos_df.to_csv(out_path / f\"{t}_oos_summary_{stamp}.csv\", index=False)\n",
    "\n",
    "    # combined save\n",
    "    stamp = pd.Timestamp.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    if all_wf:\n",
    "        wf_all = pd.concat(all_wf, ignore_index=True)\n",
    "        wf_all.to_csv(out_path / f\"ALL_walkforward_{stamp}.csv\", index=False)\n",
    "\n",
    "    if all_param:\n",
    "        param_all = pd.concat(all_param, ignore_index=True)\n",
    "        param_all.to_csv(out_path / f\"ALL_param_summary_{stamp}.csv\", index=False)\n",
    "\n",
    "    if all_oos:\n",
    "        oos_all = pd.concat(all_oos, ignore_index=True)\n",
    "        oos_all.to_csv(out_path / f\"ALL_oos_summary_{stamp}.csv\", index=False)\n",
    "\n",
    "    print(f\"Saved results to: {out_path.resolve()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "\n",
    "def make_param_grid(\n",
    "    n_list=(12, 16, 18),\n",
    "    m_list=(250, 300, 600),\n",
    "    s_list=(0.5, 0.6, 0.7),\n",
    "    variants=(\"z_right\",),          # keep fast; optionally add \"z_adj\"\n",
    "    ma_lens=(0, 5, 10, 20),\n",
    ") -> list[RSRSParams]:\n",
    "    return [\n",
    "        RSRSParams(n=n, m=m, s=s, variant=v, ma_len=ma)\n",
    "        for n, m, s, v, ma in itertools.product(n_list, m_list, s_list, variants, ma_lens)\n",
    "    ]\n",
    "\n",
    "\n",
    "def year_windows(index: pd.DatetimeIndex, train_years: int = 5, test_years: int = 1) -> list[tuple[pd.Timestamp, pd.Timestamp, pd.Timestamp, pd.Timestamp]]:\n",
    "    \"\"\"\n",
    "    Expanding-start, rolling-end style similar to your earlier prints:\n",
    "    - Train: from first date up to year-end of (start_year + train_years - 1)\n",
    "    - Test: next year(s)\n",
    "    \"\"\"\n",
    "    idx = pd.DatetimeIndex(index).sort_values()\n",
    "    start_date = idx.min()\n",
    "    start_year = start_date.year\n",
    "    last_year = idx.max().year\n",
    "\n",
    "    windows = []\n",
    "    train_start = start_date\n",
    "\n",
    "    for test_start_year in range(start_year + train_years, last_year - test_years + 1):\n",
    "        train_end = pd.Timestamp(year=test_start_year - 1, month=12, day=31)\n",
    "        test_start = pd.Timestamp(year=test_start_year, month=1, day=1)\n",
    "        test_end = pd.Timestamp(year=test_start_year + test_years - 1, month=12, day=31)\n",
    "\n",
    "        # snap to available trading days by slicing later (no need perfect day alignment here)\n",
    "        windows.append((train_start, train_end, test_start, test_end))\n",
    "\n",
    "    return windows\n",
    "\n",
    "\n",
    "def rsrs_timing_weights(\n",
    "    ohlc: pd.DataFrame,\n",
    "    trade_ticker: str,\n",
    "    n: int = 16,\n",
    "    m: int = 300,\n",
    "    s: float = 0.7,\n",
    "    variant: Literal[\"z\", \"z_adj\", \"z_right\"] = \"z_right\",\n",
    "    ma_len: int = 20,                 # set 0 to disable MA filter\n",
    "    ma_compare_lag1: int = 1,\n",
    "    ma_compare_lag2: int = 3,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Decision-time weights (as-of close t), UN-SHIFTED.\n",
    "    backtest_weights() will apply shift(1) to enforce no-lookahead.\n",
    "\n",
    "    Hysteresis:\n",
    "      - score < -s  => state = 0\n",
    "      - score > +s  => state = 1 IF (MA filter ok or disabled)\n",
    "      - else hold previous\n",
    "    \"\"\"\n",
    "    score = rsrs_indicator(ohlc=ohlc, n=n, m=m, variant=variant)\n",
    "    close = ohlc[\"Close\"].astype(float)\n",
    "\n",
    "    if ma_len is None or ma_len <= 0:\n",
    "        ma_ok = pd.Series(True, index=ohlc.index)\n",
    "    else:\n",
    "        ma = close.rolling(ma_len).mean()\n",
    "        ma_ok = ma.shift(ma_compare_lag1) > ma.shift(ma_compare_lag2)\n",
    "\n",
    "    w = pd.Series(0.0, index=ohlc.index, dtype=float)\n",
    "    state = 0.0\n",
    "\n",
    "    for i in range(len(w)):\n",
    "        sc = score.iat[i]\n",
    "        ok = bool(ma_ok.iat[i])\n",
    "\n",
    "        if not np.isfinite(sc):\n",
    "            w.iat[i] = state\n",
    "            continue\n",
    "\n",
    "        if sc < -s:\n",
    "            state = 0.0\n",
    "        elif sc > s:\n",
    "            if ok:\n",
    "                state = 1.0\n",
    "            # else hold\n",
    "        # else hold\n",
    "\n",
    "        w.iat[i] = state\n",
    "\n",
    "    return pd.DataFrame({trade_ticker: w})\n",
    "\n",
    "\n",
    "def walkforward_oos_optimize_one_ticker(\n",
    "    ticker: str,\n",
    "    ohlc: pd.DataFrame,\n",
    "    start: str,\n",
    "    end: str,\n",
    "    grid: list[RSRSParams],\n",
    "    fee_bps: float = 0.0,\n",
    "    rf_annual: float = 0.0,\n",
    "    train_years: int = 5,\n",
    "    test_years: int = 1,\n",
    "    select_metric: str = \"sharpe\",\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - oos_summary (1 row)\n",
    "      - param_summary (grouped stats per param set)\n",
    "      - walkforward_detail (per window selection + OOS stats)\n",
    "    \"\"\"\n",
    "    # tradable price\n",
    "    price_col = \"Adj Close\" if \"Adj Close\" in ohlc.columns else \"Close\"\n",
    "    px = ohlc[price_col].astype(float)\n",
    "    prices = pd.DataFrame({ticker: px}, index=ohlc.index)\n",
    "\n",
    "    # cache: per param => full-sample backtest result\n",
    "    cache = {}\n",
    "    for p in grid:\n",
    "        w = rsrs_timing_weights(\n",
    "            ohlc=ohlc,\n",
    "            trade_ticker=ticker,\n",
    "            n=p.n, m=p.m, s=p.s,\n",
    "            variant=p.variant,\n",
    "            ma_len=p.ma_len,\n",
    "            ma_compare_lag1=1,\n",
    "            ma_compare_lag2=3,\n",
    "        )\n",
    "        res = backtest_weights(\n",
    "            prices=prices,\n",
    "            weights=w,\n",
    "            fee_bps=fee_bps,\n",
    "            rf_annual=rf_annual,\n",
    "            long_only=True,\n",
    "            allow_leverage=False,\n",
    "            fill_weights=\"zero\",\n",
    "        )\n",
    "        cache[p] = (w, res)\n",
    "\n",
    "    # windows\n",
    "    wins = year_windows(prices.index, train_years=train_years, test_years=test_years)\n",
    "\n",
    "    wf_rows = []\n",
    "    oos_concat = []\n",
    "\n",
    "    for (train_start, train_end, test_start, test_end) in wins:\n",
    "        # slice masks\n",
    "        train_mask = (prices.index >= train_start) & (prices.index <= train_end)\n",
    "        test_mask = (prices.index >= test_start) & (prices.index <= test_end)\n",
    "\n",
    "        # skip empty test slices\n",
    "        if test_mask.sum() < 10:\n",
    "            continue\n",
    "\n",
    "        # select best param on train\n",
    "        best_p = None\n",
    "        best_val = -np.inf\n",
    "\n",
    "        for p in grid:\n",
    "            _, res = cache[p]\n",
    "            r_train = res.net_ret.loc[train_mask]\n",
    "\n",
    "            st = perf_stats(r_train)\n",
    "            val = st.get(select_metric, np.nan)\n",
    "            if np.isfinite(val) and val > best_val:\n",
    "                best_val = val\n",
    "                best_p = p\n",
    "\n",
    "        if best_p is None:\n",
    "            continue\n",
    "\n",
    "        # evaluate OOS on test\n",
    "        _, res_best = cache[best_p]\n",
    "        r_test = res_best.net_ret.loc[test_mask]\n",
    "        st_oos = perf_stats(r_test)\n",
    "\n",
    "        oos_concat.append(r_test)\n",
    "\n",
    "        wf_rows.append({\n",
    "            \"ticker\": ticker,\n",
    "            \"train_start\": str(pd.Timestamp(train_start).date()),\n",
    "            \"train_end\": str(pd.Timestamp(train_end).date()),\n",
    "            \"test_start\": str(pd.Timestamp(test_start).date()),\n",
    "            \"test_end\": str(pd.Timestamp(test_end).date()),\n",
    "            \"sel_metric_train\": float(best_val),\n",
    "            \"n\": best_p.n,\n",
    "            \"m\": best_p.m,\n",
    "            \"s\": best_p.s,\n",
    "            \"variant\": best_p.variant,\n",
    "            \"ma_len\": best_p.ma_len,\n",
    "            \"oos_ann_ret\": st_oos[\"ann_ret\"],\n",
    "            \"oos_ann_vol\": st_oos[\"ann_vol\"],\n",
    "            \"oos_sharpe\": st_oos[\"sharpe\"],\n",
    "            \"oos_max_dd\": st_oos[\"max_dd\"],\n",
    "            \"oos_total_return\": st_oos[\"total_return\"],\n",
    "            \"oos_avg_exposure\": float(res_best.exposure.loc[test_mask].mean()),\n",
    "            \"oos_turnover\": float(res_best.turnover.loc[test_mask].sum()),\n",
    "        })\n",
    "\n",
    "    walkforward_detail = pd.DataFrame(wf_rows)\n",
    "\n",
    "    # OOS concatenated summary\n",
    "    if len(oos_concat) == 0:\n",
    "        oos_summary = pd.DataFrame([{\n",
    "            \"ticker\": ticker,\n",
    "            \"oos_ann_ret\": 0.0,\n",
    "            \"oos_ann_vol\": 0.0,\n",
    "            \"oos_sharpe\": np.nan,\n",
    "            \"oos_max_dd\": 0.0,\n",
    "            \"oos_total_return\": 0.0,\n",
    "        }])\n",
    "    else:\n",
    "        oos_all = pd.concat(oos_concat).sort_index()\n",
    "        st_all = perf_stats(oos_all)\n",
    "        oos_summary = pd.DataFrame([{\n",
    "            \"ticker\": ticker,\n",
    "            \"oos_ann_ret\": st_all[\"ann_ret\"],\n",
    "            \"oos_ann_vol\": st_all[\"ann_vol\"],\n",
    "            \"oos_sharpe\": st_all[\"sharpe\"],\n",
    "            \"oos_max_dd\": st_all[\"max_dd\"],\n",
    "            \"oos_total_return\": st_all[\"total_return\"],\n",
    "        }])\n",
    "\n",
    "    # Param summary: average OOS Sharpe across windows where selected\n",
    "    if walkforward_detail.empty:\n",
    "        param_summary = pd.DataFrame(columns=[\n",
    "            \"ticker\",\"n\",\"m\",\"s\",\"variant\",\"ma_len\",\n",
    "            \"mean_oos_sharpe\",\"med_oos_sharpe\",\"mean_oos_ann_ret\",\"mean_oos_max_dd\",\"n_windows\"\n",
    "        ])\n",
    "    else:\n",
    "        g = walkforward_detail.groupby([\"ticker\",\"n\",\"m\",\"s\",\"variant\",\"ma_len\"])\n",
    "        param_summary = g.agg(\n",
    "            mean_oos_sharpe=(\"oos_sharpe\",\"mean\"),\n",
    "            med_oos_sharpe=(\"oos_sharpe\",\"median\"),\n",
    "            mean_oos_ann_ret=(\"oos_ann_ret\",\"mean\"),\n",
    "            mean_oos_max_dd=(\"oos_max_dd\",\"mean\"),\n",
    "            n_windows=(\"oos_sharpe\",\"count\"),\n",
    "        ).reset_index().sort_values([\"ticker\",\"mean_oos_sharpe\"], ascending=[True, False])\n",
    "\n",
    "    return oos_summary, param_summary, walkforward_detail"
   ],
   "id": "ca9803cd2ca15ae6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "\n",
    "tickers = [\"^HSI\", \"^GSPC\", \"^N225\", \"^STOXX\"]  # add/remove as needed\n",
    "start = \"2000-01-01\"\n",
    "end = \"2025-12-31\"\n",
    "\n",
    "fee_bps = 0.0\n",
    "rf_annual = 0.0\n",
    "\n",
    "train_years = 5\n",
    "test_years = 1\n",
    "\n",
    "grid = make_param_grid(\n",
    "    n_list=(12, 16, 18),\n",
    "    m_list=(250, 300, 600),\n",
    "    s_list=(0.5, 0.6, 0.7),\n",
    "    variants=(\"z_right\",),          # keep fast; add \"z_adj\" if you want\n",
    "    ma_lens=(0, 5, 10, 20),\n",
    ")\n",
    "\n",
    "all_oos = []\n",
    "all_param = []\n",
    "all_wf = []\n",
    "\n",
    "for tk in tickers:\n",
    "    print(f\"\\n=== Running {tk} ===\")\n",
    "    ohlc = download_ohlc_yf(tk, start=start, end=end, auto_adjust=False)\n",
    "\n",
    "    oos_summary, param_summary, walkforward_detail = walkforward_oos_optimize_one_ticker(\n",
    "        ticker=tk,\n",
    "        ohlc=ohlc,\n",
    "        start=start,\n",
    "        end=end,\n",
    "        grid=grid,\n",
    "        fee_bps=fee_bps,\n",
    "        rf_annual=rf_annual,\n",
    "        train_years=train_years,\n",
    "        test_years=test_years,\n",
    "        select_metric=\"sharpe\",\n",
    "    )\n",
    "\n",
    "    all_oos.append(oos_summary)\n",
    "    all_param.append(param_summary)\n",
    "    all_wf.append(walkforward_detail)\n",
    "\n",
    "ALL_oos_summary = pd.concat(all_oos, ignore_index=True)\n",
    "ALL_param_summary = pd.concat(all_param, ignore_index=True)\n",
    "ALL_walkforward = pd.concat(all_wf, ignore_index=True)\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "ALL_oos_summary.to_csv(f\"ALL_oos_summary_{ts}.csv\", index=False)\n",
    "ALL_param_summary.to_csv(f\"ALL_param_summary_{ts}.csv\", index=False)\n",
    "ALL_walkforward.to_csv(f\"ALL_walkforward_{ts}.csv\", index=False)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(f\"  ALL_oos_summary_{ts}.csv\")\n",
    "print(f\"  ALL_param_summary_{ts}.csv\")\n",
    "print(f\"  ALL_walkforward_{ts}.csv\")\n",
    "\n",
    "print(\"\\n=== ALL OOS Summary ===\")\n",
    "print(ALL_oos_summary.sort_values(\"oos_sharpe\", ascending=False).to_string(index=False))"
   ],
   "id": "dfb8cfde4e623b1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5a20542043ad3795",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
